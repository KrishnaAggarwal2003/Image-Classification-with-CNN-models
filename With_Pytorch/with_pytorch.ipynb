{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hfF51HKc6gy1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from tensorflow.keras import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD18noN-Fd4v",
        "outputId": "4b1238a0-8105-4095-e904-6d4caa711961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CY5aylNN6gy4"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WNVfXsnv6gy5"
      },
      "outputs": [],
      "source": [
        "x_train = torch.tensor(x_train / 255.0, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test / 255.0, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ijiLG8cd6gy6"
      },
      "outputs": [],
      "source": [
        "y_train = torch.tensor(y_train, dtype=torch.long).squeeze()\n",
        "y_test = torch.tensor(y_test, dtype=torch.long).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UQz9QUUBBTwJ"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoded(tensor_array, label_num=10):\n",
        "    torch_tensor = torch.zeros(tensor_array.size(0),label_num)\n",
        "    torch_tensor[[i for i in range(len(tensor_array))], tensor_array] = 1\n",
        "    return torch_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO7D-oHi6gy7",
        "outputId": "461f21e4-1cba-4a0b-c70e-7b2d96f93dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([10, 3, 32, 32]) torch.Size([10, 10])\n"
          ]
        }
      ],
      "source": [
        "train_dataset=TensorDataset(x_train.reshape(-1,3,32,32),one_hot_encoded(y_train))\n",
        "train_data_loader=DataLoader(train_dataset , batch_size=10, shuffle=True)\n",
        "\n",
        "for data, target in train_data_loader:\n",
        "    print(\"Batch shape:\", data.shape, target.shape)\n",
        "\n",
        "    # To check sample shape\n",
        "    assert data.shape[1:] == (3, 32, 32), f\"Invalid sample shape: {data.shape[1:]}\"\n",
        "    break  # Just check first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZChPpPbR6gy9"
      },
      "outputs": [],
      "source": [
        "# CNN Model\n",
        "class Convolution_model(nn.Module):\n",
        "    def __init__(self, input_size=(3,32,32)):\n",
        "        super(Convolution_model, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.conv_layer_01 = nn.Conv2d(in_channels=3 , out_channels=32, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv_layer_02 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "        self.flattened_size = self.convolution_output_size()\n",
        "        self.fc1 = nn.Linear(self.flattened_size , 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "        self.conv_activation = nn.ReLU()\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def convolution_output_size(self):\n",
        "        with torch.no_grad():\n",
        "          dummy_target = torch.randn(1, *self.input_size)\n",
        "          output = self.conv_layer_01(dummy_target)\n",
        "          output = self.pool_layer(output)\n",
        "          output = self.conv_layer_02(output)\n",
        "          output = self.pool_layer(output)\n",
        "        return output.view(1,-1).size(1)\n",
        "\n",
        "    def forward(self, img_data):\n",
        "\n",
        "        if img_data.shape[1:] != self.input_size:\n",
        "            raise ValueError(f\"Expected shape: {self.input_size} got {img_data.shape}\")\n",
        "\n",
        "        conv_layer_01 = self.conv_activation(self.conv_layer_01(img_data))\n",
        "        pooled_01 = self.pool_layer(conv_layer_01)\n",
        "        conv_layer_02 = self.conv_activation(self.conv_layer_02(pooled_01))\n",
        "        pooled_02 = self.pool_layer(conv_layer_02)\n",
        "        dense_input = pooled_02.view(pooled_02.size(0),-1)\n",
        "        dense_01 = self.activation(self.fc1(dense_input))\n",
        "        prob_values = torch.softmax(self.fc2(dense_01), dim=1)\n",
        "        return prob_values\n",
        "\n",
        "\n",
        "def train_model(model,train_datasets,learning_rate,num_epochs):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for data,target in train_datasets:\n",
        "            data,target = data.float() , target.float()\n",
        "            data,target = data.to(device),target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model.forward(data)\n",
        "            loss_value = criterion(output,target)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            total_loss +=loss_value.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_datasets)\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
        "            print(f\"Epoch : {epoch}/{num_epochs} and Loss value: {avg_loss:.5f}\")\n",
        "\n",
        "    print(f\"Training completed with total epochs: {num_epochs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUHuqNu26gy_",
        "outputId": "d64e3087-0c30-4f42-d0dc-1d5f86e1b059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The flattened layer after whole convolution:- 2304\n"
          ]
        }
      ],
      "source": [
        "conv_model = Convolution_model()\n",
        "\n",
        "print(f\"The flattened layer after whole convolution:- {conv_model.convolution_output_size()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "d5d7f242b7f64c7f9fcd1e3cfa455079",
            "481a0f84fe804f4ca14cf0afc87a3fb6",
            "dd7704493a714c7487d1467bc3d2b7ba",
            "d4482b1c545847bd985074eb429c3c0b",
            "d1f187e740144676938a80490628eb24",
            "5a50e8bea7c14ce4957976d4af058184",
            "616bb3ffe8f047c586b86becf9221dac",
            "0b526bf5331e4516ba413e9a84f3637d",
            "6e81c70a24cf408fb7d637c981a252b7",
            "535aa4ffcb98469f89bb2c42ce1494e5",
            "7698ee56323a42d895862451424f09df"
          ]
        },
        "id": "2IJvNoS_6gzA",
        "outputId": "7d680536-932f-4463-c260-b132c4a82c33"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5d7f242b7f64c7f9fcd1e3cfa455079",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0/200 and Loss value: 2.19923\n",
            "Epoch : 10/200 and Loss value: 1.97565\n",
            "Epoch : 20/200 and Loss value: 1.89112\n",
            "Epoch : 30/200 and Loss value: 1.82061\n",
            "Epoch : 40/200 and Loss value: 1.76595\n",
            "Epoch : 50/200 and Loss value: 1.73131\n",
            "Epoch : 60/200 and Loss value: 1.70918\n",
            "Epoch : 70/200 and Loss value: 1.69468\n",
            "Epoch : 80/200 and Loss value: 1.68319\n",
            "Epoch : 90/200 and Loss value: 1.67533\n",
            "Epoch : 100/200 and Loss value: 1.66883\n",
            "Epoch : 110/200 and Loss value: 1.66375\n",
            "Epoch : 120/200 and Loss value: 1.65839\n",
            "Epoch : 130/200 and Loss value: 1.65612\n",
            "Epoch : 140/200 and Loss value: 1.65229\n",
            "Epoch : 150/200 and Loss value: 1.64909\n",
            "Epoch : 160/200 and Loss value: 1.64802\n",
            "Epoch : 170/200 and Loss value: 1.64498\n",
            "Epoch : 180/200 and Loss value: 1.64329\n",
            "Epoch : 190/200 and Loss value: 1.64097\n",
            "Epoch : 199/200 and Loss value: 1.64037\n",
            "Training completed with total epochs: 200\n"
          ]
        }
      ],
      "source": [
        "karpathy_constant = 3e-4\n",
        "\n",
        "train_model(model = conv_model , train_datasets = train_data_loader , learning_rate = karpathy_constant , num_epochs = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L1M0WwBFd42",
        "outputId": "061aea72-5b06-44c6-aebd-9f0ff76d4e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters loaded from file: \n",
            "odict_keys(['conv_layer_01.weight', 'conv_layer_01.bias', 'conv_layer_02.weight', 'conv_layer_02.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
          ]
        }
      ],
      "source": [
        "# Model Serialization:- Saving up the model parameters after training phase\n",
        "\n",
        "torch.save(conv_model.state_dict(), 'pytorch_parameters.pth')\n",
        "parameters = torch.load('pytorch_parameters.pth' , map_location = 'cpu')\n",
        "print(f\"Model parameters loaded from file: \\n{parameters.keys()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-9HvHelFd42",
        "outputId": "8b9c98a8-5651-403e-f0c9-1791deb8cbe7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Convolution_model(\n",
              "  (conv_layer_01): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer_02): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=2304, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (conv_activation): ReLU()\n",
              "  (activation): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_model = Convolution_model()\n",
        "new_model.load_state_dict(torch.load('pytorch_parameters.pth'))\n",
        "new_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZBx3TRUFd43",
        "outputId": "ed0b884e-0811-4918-f901-4ae389220eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly predicted: 4765 and Wrongly predicted: 5235\n",
            "Total test data: 10000\n",
            "Accuracy of the model: 47.65%\n"
          ]
        }
      ],
      "source": [
        "correct_predicted = 0\n",
        "wrong_predicted = 0\n",
        "\n",
        "for i,data in enumerate(x_test):\n",
        "    data = data.reshape(1,3,32,32).float()\n",
        "    predicted_value = torch.argmax(new_model.forward(data)).item()\n",
        "    if predicted_value == y_test[i].item():\n",
        "        correct_predicted += 1\n",
        "    else:\n",
        "        wrong_predicted += 1\n",
        "\n",
        "print(f\"Correctly predicted: {correct_predicted} and Wrongly predicted: {wrong_predicted}\")\n",
        "print(f\"Total test data: {len(x_test)}\")\n",
        "print(f\"Accuracy of the model: {correct_predicted / len(x_test) * 100:.2f}%\")\n",
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}