{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hfF51HKc6gy1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from tensorflow.keras import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD18noN-Fd4v",
        "outputId": "edf5dad1-7dde-49d9-c9c5-de5643bb3fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CY5aylNN6gy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb7c9ba-6b64-42ed-d33f-8281e853f646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WNVfXsnv6gy5"
      },
      "outputs": [],
      "source": [
        "x_train = torch.tensor(x_train / 255.0, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test / 255.0, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ijiLG8cd6gy6"
      },
      "outputs": [],
      "source": [
        "y_train = torch.tensor(y_train, dtype=torch.long).squeeze()\n",
        "y_test = torch.tensor(y_test, dtype=torch.long).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UQz9QUUBBTwJ"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoded(tensor_array, label_num=10):\n",
        "    torch_tensor = torch.zeros(tensor_array.size(0),label_num)\n",
        "    torch_tensor[[i for i in range(len(tensor_array))], tensor_array] = 1\n",
        "    return torch_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO7D-oHi6gy7",
        "outputId": "4c663adf-f509-4fe1-fafa-941738530cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([10, 3, 32, 32]) torch.Size([10, 10])\n"
          ]
        }
      ],
      "source": [
        "train_dataset=TensorDataset(torch.movedim(x_train,3,1),one_hot_encoded(y_train))\n",
        "train_data_loader=DataLoader(train_dataset , batch_size=10, shuffle=True)\n",
        "\n",
        "for data, target in train_data_loader:\n",
        "    print(\"Batch shape:\", data.shape, target.shape)\n",
        "\n",
        "    # To check sample shape\n",
        "    assert data.shape[1:] == (3, 32, 32), f\"Invalid sample shape: {data.shape[1:]}\"\n",
        "    break  # Just check first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZChPpPbR6gy9"
      },
      "outputs": [],
      "source": [
        "# CNN Model\n",
        "class Convolution_model(nn.Module):\n",
        "    def __init__(self, input_size=(3,32,32)):\n",
        "        super(Convolution_model, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.conv_layer_01 = nn.Conv2d(in_channels=3 , out_channels=32, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv_layer_02 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "        self.flattened_size = self.convolution_output_size()\n",
        "        self.fc1 = nn.Linear(self.flattened_size , 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "        self.conv_activation = nn.ReLU()\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def convolution_output_size(self):\n",
        "        with torch.no_grad():\n",
        "          dummy_target = torch.randn(1, *self.input_size)\n",
        "          output = self.conv_layer_01(dummy_target)\n",
        "          output = self.pool_layer(output)\n",
        "          output = self.conv_layer_02(output)\n",
        "          output = self.pool_layer(output)\n",
        "        return output.view(1,-1).size(1)\n",
        "\n",
        "    def forward(self, img_data):\n",
        "\n",
        "        if img_data.shape[1:] != self.input_size:\n",
        "            raise ValueError(f\"Expected shape: {self.input_size} got {img_data.shape}\")\n",
        "\n",
        "        conv_layer_01 = self.conv_activation(self.conv_layer_01(img_data))\n",
        "        pooled_01 = self.pool_layer(conv_layer_01)\n",
        "        conv_layer_02 = self.conv_activation(self.conv_layer_02(pooled_01))\n",
        "        pooled_02 = self.pool_layer(conv_layer_02)\n",
        "        dense_input = pooled_02.view(pooled_02.size(0),-1)\n",
        "        dense_01 = self.activation(self.fc1(dense_input))\n",
        "        prob_values = torch.softmax(self.fc2(dense_01), dim=1)\n",
        "        return prob_values\n",
        "\n",
        "\n",
        "def train_model(model,train_datasets,learning_rate,num_epochs):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for data,target in train_datasets:\n",
        "            data,target = data.float() , target.float()\n",
        "            data,target = data.to(device),target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model.forward(data)\n",
        "            loss_value = criterion(output,target)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            total_loss +=loss_value.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_datasets)\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
        "            print(f\"Epoch : {epoch}/{num_epochs} and Loss value: {avg_loss:.5f}\")\n",
        "\n",
        "    print(f\"Training completed with total epochs: {num_epochs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUHuqNu26gy_",
        "outputId": "df324138-bf08-4063-8f39-9320f86c85b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The flattened layer after whole convolution:- 2304\n"
          ]
        }
      ],
      "source": [
        "conv_model = Convolution_model()\n",
        "\n",
        "print(f\"The flattened layer after whole convolution:- {conv_model.convolution_output_size()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "0921cfda81684988a22af36962c36ecc",
            "6270d25f122b4343b237f3ca851e913b",
            "cdc69eeda3ee4a8ca89bae1bb60ab7bd",
            "94b955c9800d4db9a6d3d2de5b2c1dd9",
            "aa683e015fb9412c95dbd725ea9204d6",
            "9974b27b5c5a42e0ae4cd33e58e2d8f4",
            "759554890eea4a01b5e72d5d690eb26f",
            "e0b0ffb0b5d542b4a5bd8f421bab3c48",
            "a47954b1653a4b94beeb0af0cddbae6a",
            "03fb18ec67bf4eed9413834f1adb1488",
            "307b0d252cd6488798e2b6dae294823b"
          ]
        },
        "id": "2IJvNoS_6gzA",
        "outputId": "dfe4f59f-fbae-400b-d0fe-08170459d2b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0921cfda81684988a22af36962c36ecc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0/200 and Loss value: 2.12310\n",
            "Epoch : 10/200 and Loss value: 1.76541\n",
            "Epoch : 20/200 and Loss value: 1.66625\n",
            "Epoch : 30/200 and Loss value: 1.60936\n",
            "Epoch : 40/200 and Loss value: 1.58233\n",
            "Epoch : 50/200 and Loss value: 1.56807\n",
            "Epoch : 60/200 and Loss value: 1.55920\n",
            "Epoch : 70/200 and Loss value: 1.55494\n",
            "Epoch : 80/200 and Loss value: 1.55009\n",
            "Epoch : 90/200 and Loss value: 1.54746\n",
            "Epoch : 100/200 and Loss value: 1.54506\n",
            "Epoch : 110/200 and Loss value: 1.54304\n",
            "Epoch : 120/200 and Loss value: 1.54110\n",
            "Epoch : 130/200 and Loss value: 1.53981\n",
            "Epoch : 140/200 and Loss value: 1.53797\n",
            "Epoch : 150/200 and Loss value: 1.53697\n",
            "Epoch : 160/200 and Loss value: 1.53579\n",
            "Epoch : 170/200 and Loss value: 1.53440\n",
            "Epoch : 180/200 and Loss value: 1.53441\n",
            "Epoch : 190/200 and Loss value: 1.53330\n",
            "Epoch : 199/200 and Loss value: 1.53262\n",
            "Training completed with total epochs: 200\n"
          ]
        }
      ],
      "source": [
        "karpathy_constant = 3e-4\n",
        "\n",
        "train_model(model = conv_model , train_datasets = train_data_loader , learning_rate = karpathy_constant , num_epochs = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3L1M0WwBFd42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f1f807-63b9-417c-b473-08e15ac1078b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters loaded from file: \n",
            "odict_keys(['conv_layer_01.weight', 'conv_layer_01.bias', 'conv_layer_02.weight', 'conv_layer_02.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
          ]
        }
      ],
      "source": [
        "# Model Serialization:- Saving up the model parameters after training phase\n",
        "\n",
        "torch.save(conv_model.state_dict(), 'pytorch_parameters.pth')\n",
        "parameters = torch.load('pytorch_parameters.pth' , map_location = 'cpu')\n",
        "print(f\"Model parameters loaded from file: \\n{parameters.keys()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "O-9HvHelFd42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d68138-d63d-4add-9ecc-bb7e686a41c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Convolution_model(\n",
              "  (conv_layer_01): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer_02): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=2304, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (conv_activation): ReLU()\n",
              "  (activation): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "new_model = Convolution_model()\n",
        "new_model.load_state_dict(torch.load('pytorch_parameters.pth'))\n",
        "new_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PZBx3TRUFd43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029a4725-a1a6-4f60-828c-8e5dfbd34087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly predicted: 6714 and Wrongly predicted: 3286\n",
            "Total test data: 10000\n",
            "Accuracy of the model: 67.14%\n"
          ]
        }
      ],
      "source": [
        "correct_predicted = 0\n",
        "wrong_predicted = 0\n",
        "\n",
        "for i,data in enumerate(x_test):\n",
        "    predicted_value = torch.argmax(new_model.forward(torch.movedim(data,2,0).unsqueeze(dim=0).float())).item()\n",
        "    if predicted_value == y_test[i].item():\n",
        "        correct_predicted += 1\n",
        "    else:\n",
        "        wrong_predicted += 1\n",
        "\n",
        "print(f\"Correctly predicted: {correct_predicted} and Wrongly predicted: {wrong_predicted}\")\n",
        "print(f\"Total test data: {len(x_test)}\")\n",
        "print(f\"Accuracy of the model: {correct_predicted / len(x_test) * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}